{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1 id=\"toctitle\">Performance and benchmarking</h1>\n",
      "<ul id=\"toc\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "Distinct but related concepts:\n",
      "\n",
      "- Measuring\n",
      "    - Benchmarking (how long does something take)\n",
      "        - CPU\n",
      "        - Memory (less so)\n",
      "    - Profiling (which bits are slow)\n",
      "        - CPU\n",
      "        - ~~Memory~~ (not today)\n",
      "- Optimizing\n",
      "\n",
      "As with most programming jobs, a range of tools from simple to complex.\n",
      "\n",
      "## Benchmarking\n",
      "\n",
      "In approximate order of usefulness....\n",
      "\n",
      "### Unix time\n",
      "How long does our program take to run? On Linux/Mac we can do \n",
      "\n",
      "```\n",
      "time somecommand\n",
      "```\n",
      "\n",
      "In iPython, prefix shell commands with `!`\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given output that looks like this:\n",
      "\n",
      "```\n",
      "real\t0m0.490s \n",
      "user\t0m0.457s \n",
      "sys\t    0m0.032s \n",
      "```\n",
      "\n",
      "- real is the wallclock time (affected by busy systems and other programs)\n",
      "- user is the time spent executing our code\n",
      "- sys is the time spent waiting for system calls (file IO, memory, network)\n",
      "\n",
      "user+sys is probably the most useful. \n",
      "\n",
      "### Manual timing\n",
      "\n",
      "Just measure the current time at the start of code, then again at end, and get the difference. \n",
      "\n",
      "`time.time()` gives us current UNIX epoch (number of seconds since midnight January 1st 1970 (don't ask.))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time \n",
      "time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On most systems this has very high resolution. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time \n",
      "start = time.time() \n",
      "\n",
      "# print the sum of the first million cube numbers\n",
      "x = 0 \n",
      "for i in range(1000000): \n",
      "    x = x + i ** 3 \n",
      "print(x) \n",
      " \n",
      "end = time.time() \n",
      "print(end - start) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is arguably better than using the `time` command line as it doesn't include Python start up time, etc. However, still affected by other processes.\n",
      "\n",
      "### `timeit` module\n",
      "\n",
      "Python has a built in module for doing timing. From the command line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python -m timeit \"4 ** 10\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nice features:\n",
      "- automatically runs the code many times to get an accurate measurement\n",
      "- runs the whole thing three times and reports the best (accounts for other processes)\n",
      "- gives the answer in easy to read units:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python -m timeit \"12345 in range(1000000)\" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the above code, do we spend more time constructing the range list or checking if the number is in it? Let's try just constructing the range:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python -m timeit \"range(1000000)\" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yep, takes loads of time to construct the list. Seperate that bit out with a setup (`-s`) command:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python -m timeit -s \"r=range(1000000)\" \"12345 in r\" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In iPython, we have magic convenience functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit 4 ** 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r=range(1000000)\n",
      "%timeit 12345 in r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "# print the sum of the first million cube numbers\n",
      "x = 0 \n",
      "for i in range(1000000): \n",
      "    x = x + i ** 3 \n",
      "#print(x) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`timeit` is useful for quickly checking which approach is faster. `timeit` case study: which way is faster to calculate AT content - counting a and t, or looking at each base and keeping a tally?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division \n",
      "\n",
      "def at_count(dna): \n",
      "    return (dna.count('a') + dna.count('t')) / len(dna) \n",
      " \n",
      "def at_iter(dna): \n",
      "    a_count = 0 \n",
      "    t_count = 0 \n",
      "    for base in dna: \n",
      "        if base == 'a': \n",
      "            a_count = a_count + 1 \n",
      "        elif base == 't': \n",
      "            t_count = t_count + 1 \n",
      "    return (a_count + t_count) / len(dna) \n",
      "\n",
      "test_dna = 'atcgatcgatcatgatcggatcgtagctagcatctagtc' \n",
      "assert(at_count(test_dna) == at_iter(test_dna)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is faster?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit at_count(test_dna)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit at_iter(test_dna)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmmm, something odd is going on. Short strings don't give reliable benchmarking results in Python due to optimizations in cPython. Let's try a more realistic input:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "def random_dna(length):\n",
      "    return \"\".join([random.choice(['A','T','G','C']) for _ in range(length)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_dna(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can compare the two functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit at_count(random_dna(10000))\n",
      "%timeit at_iter(random_dna(10000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks about equal, but wait: what if most of the time is spent generating the random DNA sequence? This is fairer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = random_dna(10000)\n",
      "%timeit at_count(d)\n",
      "%timeit at_iter(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Summary: \n",
      "\n",
      "- getting timing right is hard\n",
      "- `count()` is faster than iteration (due to fast C code)\n",
      "\n",
      "### Benchmarking memory\n",
      "\n",
      "Here's the short story:\n",
      "\n",
      "`pip install psutil`\n",
      "\n",
      "then"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import psutil, os \n",
      " \n",
      "process = psutil.Process(os.getpid()) \n",
      "mem = process.get_memory_info().rss / 1000 \n",
      "print(\"Used this much memory: \" + str(mem) + ' kb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Problem: this is useless in iPython notebooks as it includes everything that's been executed. For simple scripts, it's better. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python check_mem.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This lets us investigate time/memory trade offs. We know that checking to see if a number is in a set is faster than checking to see if it's in a list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = range(1000000)\n",
      "s = set(l)\n",
      "%timeit 12345 in l\n",
      "%timeit 12345 in s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but how much longer does it take to create the data structure in the first place?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit list(range(1000000))\n",
      "%timeit set(range(1000000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and how much more memory does it take to hold the set?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python list_mem.py\n",
      "!python set_mem.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusions:\n",
      "- if we need to create a list once then check membership many times, a set will be faster\n",
      "- if we need to create many lists, a set might be slower\n",
      "- a set will use more (x1.5) memory for these ranges \n",
      "\n",
      "Of course, everything might be different for non-integers!\n",
      "\n",
      "## Profiling\n",
      "\n",
      "Profiling is the process of taking an existing piece of code and identifying which bits are taking the time. \n",
      "\n",
      "Scenario: given\n",
      "\n",
      "- a single long DNA sequence\n",
      "- a collection of interesting 4-base motifs\n",
      "\n",
      "we want to identify frequently-occuring (say 50 times) 4-base motifs in the sequence and divide them into ones that are also on the interesting list, and ones that aren't. \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# create a random dna sequence\n",
      "dna = random_dna(10000)\n",
      "\n",
      "# create 100 random interesting motifs\n",
      "motifs = [random_dna(4) for _ in range(100)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "# standard kmer counting code to identify frequent chunks\n",
      "frequent_chunks = [] \n",
      "for start in range(len(dna) - 3): \n",
      "    chunk = dna[start:start + 4] \n",
      "    if dna.count(chunk) > 50: \n",
      "        frequent_chunks.append(chunk) \n",
      "\n",
      "# now check each chunk to see if it's in the list of motifs\n",
      "for chunk in frequent_chunks: \n",
      "    if chunk in motifs: \n",
      "        print(chunk + \" is frequent and interesting\") \n",
      "    else: \n",
      "        print(chunk + \" is frequent but not interesting\")"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How can we speed this program up? We know that checking to see if an element is in a list is slow, so let's change it to a set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# create 100 random interesting motifs\n",
      "motifs = set([random_dna(4) for _ in range(100)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "# standard kmer counting code to identify frequent chunks\n",
      "frequent_chunks = [] \n",
      "for start in range(len(dna) - 3): \n",
      "    chunk = dna[start:start + 4] \n",
      "    if dna.count(chunk) > 50: \n",
      "        frequent_chunks.append(chunk) \n",
      "\n",
      "# now check each chunk to see if it's in the list of motifs\n",
      "for chunk in frequent_chunks: \n",
      "    if chunk in motifs: \n",
      "        print(chunk + \" is frequent and interesting\") \n",
      "    else: \n",
      "        print(chunk + \" is frequent but not interesting\")\n",
      "        \n",
      "print(len(frequent_chunks))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why did this not work? Probably because the line\n",
      "\n",
      "```python\n",
      "    if chunk in motifs: \n",
      "```\n",
      "\n",
      "doesn't actually get executed that often."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What we need is a way to see which lines are taking up the most time.\n",
      "\n",
      "### Profiling with cProfile\n",
      "\n",
      "`cProfile` is a built in module for profiling functions. It's easy to use:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cProfile \n",
      "\n",
      "# we have to turn the code into a function so we can pass its name to run()\n",
      "def classify_chunks():\n",
      "    frequent_chunks = [] \n",
      "    for start in range(len(dna) - 3): \n",
      "        chunk = dna[start:start + 4] \n",
      "        if dna.count(chunk) > 50: \n",
      "            frequent_chunks.append(chunk) \n",
      "\n",
      "    for chunk in frequent_chunks: \n",
      "        if chunk in motifs: \n",
      "            print(chunk + \" is frequent and interesting\") \n",
      "        else: \n",
      "            print(chunk + \" is frequent but not interesting\")\n",
      "\n",
      "cProfile.run(\"classify_chunks()\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "cProfile gives us tabular output\n",
      "\n",
      "- ncalls, which tells us how many times the function was called\n",
      "- tottime, which tells us the total amount of time that was spent in that function (not including sub functions)\n",
      "- percall, which tells us the amount of time that was spent in that function (not including sub functions) each time it was called\n",
      "- cumtime, which is like tottime but does include sub functions\n",
      "- another percall, which is like the first one except that it does include sub functions\n",
      "- filename, which tells us the filename, line number, and name of the function or method\n",
      "\n",
      "\n",
      "What can we see from the cProfile output?\n",
      "\n",
      "- the code took about 0.6 seconds to run (slightly longer than before due to overhead)\n",
      "- 17877 functions were called\n",
      "\n",
      "Let's look at some specific functions:\n",
      "\n",
      "`classify_chunks()`\n",
      "```\n",
      "ncalls  tottime  percall  cumtime  percall filename:lineno(function) \n",
      "     1  0.009    0.009    0.620    0.620   time_profile.py:13(classify_chunks) \n",
      "```\n",
      "- was called once\n",
      "- very small tottime i.e. not much going on \n",
      "- but very big cumtime, so most of time in functions called inside it\n",
      "\n",
      "`append()` method of lists\n",
      "```\n",
      "ncalls  tottime  percall  cumtime  percall filename:lineno(function) \n",
      "   419  0.000    0.000    0.000    0.000   {method 'append' of 'list' objects} \n",
      "```\n",
      "- called 419 times (once for each frequent chunk)\n",
      "- but tottime and cumtime so low they're rounded to zero\n",
      "\n",
      "`count()` method of strings\n",
      "```\n",
      "ncalls  tottime  percall  cumtime  percall filename:lineno(function) \n",
      "  9997  0.612    0.000    0.612    0.000   {method 'count' of 'str' objects} \n",
      "```\n",
      "- called around 10000 times (once per chunk in the DNA sequence)\n",
      "- percall time is very low - counting is fast\n",
      "- but tottime is big - most of the time of the program. \n",
      "\n",
      "cProfile only measures function calls, i.e. not stuff like\n",
      "\n",
      "```python\n",
      "dna[start:start + 4] \n",
      "dna.count(chunk) > 50\n",
      "chunk in motifs\n",
      "```\n",
      "To use it well, we need structured code e.g. if we split our code into two functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cProfile \n",
      "\n",
      "def get_frequent_chunks(dna): \n",
      "    frequent_chunks = [] \n",
      "    for start in range(len(dna) - 3): \n",
      "        chunk = dna[start:start + 4] \n",
      "        if dna.count(chunk) > 50: \n",
      "            frequent_chunks.append(chunk) \n",
      "    return frequent_chunks \n",
      " \n",
      "def print_chunks(chunks): \n",
      "    for chunk in chunks: \n",
      "        if chunk in motifs: \n",
      "            print(chunk + \" is frequent and interesting\") \n",
      "        else: \n",
      "            print(chunk + \" is frequent but not interesting\") \n",
      "            \n",
      "def classify_chunks(): \n",
      "    frequent_chunks = get_frequent_chunks(dna) \n",
      "    print_chunks(frequent_chunks) \n",
      "\n",
      "cProfile.run(\"classify_chunks()\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We get more useful output:\n",
      "\n",
      "```\n",
      "ncalls tottime percall   cumtime   percall filename:lineno(function) \n",
      " 1    0.005    0.005      0.619     0.619  time_profile.py:14(get_frequent_chunks)\n",
      " 1    0.004    0.004      0.004     0.004  time_profile.py:22(print_chunks) \n",
      "```\n",
      "\n",
      "Most of the time is counting the chunks, not classifying them (hence why our speed-up idea didn't work)\n",
      "\n",
      "### Profiling with line_profiler\n",
      "\n",
      "`line_profiler` is a third party module that you have to install separately:\n",
      "\n",
      "`pip install line_profiler`\n",
      "\n",
      "It measures execution time per line. To use it we add a `@profile` decorator to the function and run from the command line with:\n",
      "\n",
      "`kernprof -l -v slowfast.py`\n",
      "\n",
      "Let's try it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!kernprof -l -v chunks.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hopefully the output shows the usefulness - we can see immediately that \n",
      "\n",
      "`if dna.count(chunk) > 50:`\n",
      "\n",
      "uses 96% of the time. Let's switch to a dict and keep a tally:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def classify_chunks(): \n",
      "    chunk_count = {}\n",
      "    for start in range(len(dna) - 3):\n",
      "        chunk = dna[start:start + 4]\n",
      "        current_count = chunk_count.get(chunk, 0)\n",
      "        new_count = current_count + 1 \n",
      "        chunk_count[chunk] = new_count\n",
      "\n",
      "    for chunk, count in chunk_count.items():\n",
      "        if count > 50: \n",
      "            if chunk in motifs:\n",
      "                print(chunk + \" is frequent and interesting\")\n",
      "            else:\n",
      "                print(chunk + \" is frequent but not interesting\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!kernprof -l -v chunks.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The improvement is dramatic. We could go on from here to make further improvements. \n",
      "\n",
      "### Profiling with realistic inputs\n",
      "\n",
      "For many programs the data greatly affects the profiling results. Here are functions to calculate AT content and to check if two sequences share the same first five bases:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def at_content(dna): \n",
      "    return (dna.count('A') + dna.count('T')) / len(dna) \n",
      "\n",
      "def same_start(dna1, dna2): \n",
      "    return dna1[0:5] == dna2[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to take a large collection of DNA sequences and identify those that\n",
      "\n",
      "- have an AT content greater than some cutoff value and\n",
      "- have the same first five bases as at least one other sequence\n",
      "\n",
      "Here's a first attempt:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_interesting(dnas, cutoff):\n",
      "    interesting = set()\n",
      "    for one in dnas:\n",
      "        at = at_content(one)\n",
      "        if at > cutoff:\n",
      "            for two in dnas:\n",
      "                if one != two and same_start(one, two):\n",
      "                    interesting.add(one)\n",
      "\n",
      "    return(interesting)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which function takes the most time? Let's send it though `line_profiler` with 1000 sequences of 1000 bases and a cutoff of 0.54:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!kernprof -v -l realdata.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The calls to `at_content()` take most of the time. But, if we try a bigger dataset with 10,000 sequences:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!kernprof -v -l realdata.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now `same_start()` is taking the most time. Why? because it's in the inner loop, so the number of calls scales with the square of the size of the dataset - O(N) vs O(N<sup>2</sup>).\n",
      "\n",
      "What happens if we keep the dataset size the same at 1000 sequences, but decrease the AT content cutoff so that more sequences pass it (0.525):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!kernprof -v -l realdata.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`same_start()` dominates again. In both these cases the code is unchanged, but by changing the dataset we get opposite results about which function to optimize first. \n",
      "\n",
      "**always carry out benchmarking and profiling on realistic data!**\n",
      "\n",
      "### Performance optimization tips\n",
      "\n",
      "- File and network IO is slow, so minimize it\n",
      "- Existing modules are likely to be fast, so use them (scipy/numpy/pandas)\n",
      "- Avoid calculating the same thing multiple times\n",
      "- Functional structures (maps/comprehensions) tend to be faster than loops\n",
      "- Pick data structures with the properties you want (list vs. set)\n",
      "\n",
      "and some advanced things to know about:\n",
      "\n",
      "- write inline code in faster languages\n",
      "- use parallel code\n",
      "- let a database do the heavy lifting if you can\n",
      "\n",
      "## Exercises\n",
      "\n",
      "**no solutions for these**\n",
      "\n",
      "See how much faster you can make the `classify_chunks` function from above. What effect do the various parameters (chunk length, DNA sequence length, interesting motif count, frequency cutoff) have on the execution time? what effect do they have on the distribution of execution time across lines?\n",
      "\n",
      "On the desktop computers, run **Canopy command prompt** then the command line is:\n",
      "\n",
      "`python \"C:\\Program Files\\Enthought\\VE\\User\\Scripts\\kernprof-script.py\" -v -l path-to-script`\n",
      "\n",
      "Do the same with one of your solutions to a previous exercise, or some of your own code. \n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ignore this cell, it's for loading custom js code\n",
      "from IPython.core.display import Javascript\n",
      "Javascript(filename=\"custom.js\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ignore this cell, it's for loading custom css code\n",
      "from IPython.core.display import HTML\n",
      "HTML(filename=\"custom.css\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}