{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTA\n",
    "\n",
    "This notebook briefly explores the FASTA format, a very common format for storing DNA sequences. FASTA is the preferred format for storing reference genomes.\n",
    "\n",
    "FASTA and FASTQ are rather similar, but FASTQ is almost always used for storing sequencing reads (with associated quality values), whereas FASTA is used for storing all kinds of DNA, RNA or protein sequencines (without associated quality values).\n",
    "\n",
    "\n",
    "**Basic format**\n",
    "\n",
    "Here is the basic format:\n",
    "\n",
    "    >sequence1_short_name with optional additional info after whitespace\n",
    "    ACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA\n",
    "    GCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGAACAAGCATCAAGCACGCAGC\n",
    "    AATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGAT\n",
    "    >sequence2_short_name with optional additional info after whitespace\n",
    "    GCCCCAAACCCACTCCACCTTACTACCAGACAACCTTAGCCAAACCATTTACCCAAATAAAGTATAGGCG\n",
    "    ATAGAAATTGAAACCTGGCGCAATAGATATAGTACCGCAAGGGAAAGATGAAAAATTATAACCAAGCATA\n",
    "    ATATAG\n",
    "\n",
    "A line starting with a > (greater-than) sign indicates the beginning of a new sequence and specifies its name. Take the first line above. Everything after the > up to and excluding the first whitespace character (sequence1_short_name), is the \"short name.\" Everything after the > up to the end of the line (sequence1_short_name with optional additional info after whitespace) is the \"long name.\" We usually use the short name when referring to FASTA sequences.\n",
    "\n",
    "The next three lines consists of several nucleotides. There is a maximum number of nucleotides permitted per line; in this case, it is 70. If the sequence is longer then 70 nucleotides, it \"wraps\" down to the next line. Not every FASTA file uses the same maximum, but a given FASTA file must use the same maximum throughout the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing FASTA \n",
    "\n",
    "Here is a simple function for parsing a FASTA file into a Python dictionary. The dictionary maps short names to corresponding nucleotide strings (with whitespace removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(fh):\n",
    "    fa = {}\n",
    "    current_short_name = None\n",
    "    # Part 1: compile list of lines per sequence\n",
    "    for ln in fh:\n",
    "        if ln[0] == '>':\n",
    "            # new name line; remember current sequence's short name\n",
    "            long_name = ln[1:].rstrip()\n",
    "            current_short_name = long_name.split()[0]\n",
    "            fa[current_short_name] = []\n",
    "        else:\n",
    "            # append nucleotides to current sequence\n",
    "            fa[current_short_name].append(ln.rstrip())\n",
    "    # Part 2: join lists into strings\n",
    "    for short_name, nuc_list in fa.items():\n",
    "        # join this sequence's lines into one long string\n",
    "        fa[short_name] = ''.join(nuc_list)\n",
    "    return fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function by running it on the simple FASTA file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "fasta_example = StringIO(\n",
    "'''>sequence1_short_name with optional additional info after whitespace\n",
    "ACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA\n",
    "GCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGAACAAGCATCAAGCACGCAGC\n",
    "AATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGAT\n",
    ">sequence2_short_name with optional additional info after whitespace\n",
    "GCCCCAAACCCACTCCACCTTACTACCAGACAACCTTAGCCAAACCATTTACCCAAATAAAGTATAGGCG\n",
    "ATAGAAATTGAAACCTGGCGCAATAGATATAGTACCGCAAGGGAAAGATGAAAAATTATAACCAAGCATA\n",
    "ATATAG''')\n",
    "parsed_fa = parse_fasta(fasta_example)\n",
    "parsed_fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexed FASTA\n",
    "\n",
    "Say you have one or more big FASTA files (e.g. the entire human reference genome) and you'd like to access those files \"randomly,\" peeking at substrings here and there without any regular access pattern. Maybe you're mimicking a sequencing machine, reading snippets of DNA here and there.\n",
    "\n",
    "You could start by using the parse_fasta function defined above to parse the FASTA files. Then, to access a substring, do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_fa['sequence2_short_name'][100:130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing a substring in this way is very fast and simple. The downside is that you've stored all of the sequences in memory. If the FASTA files are really big, this takes lots of valuable memory. This may or may not be a good trade.\n",
    "\n",
    "An alternative is to load only the portions of the FASTA files that you need, when you need them. For this to be practical, we have to have a way of \"jumping\" to the specific part of the specific FASTA file that you're intersted in.\n",
    "\n",
    "Fortunately, there is a standard way of indexing a FASTA file, popularized by the faidx tool in SAMtools. When you have such an index, it's easy to calculate exactly where to jump to when you want to extract a specific substring. Here is some Python to create such an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_fasta(fh):\n",
    "    index = []\n",
    "    current_short_name = None\n",
    "    current_byte_offset, running_seq_length, running_byte_offset = 0, 0, 0\n",
    "    line_length_including_ws, line_length_excluding_ws = 0, 0\n",
    "    for ln in fh:\n",
    "        ln_stripped = ln.rstrip()\n",
    "        running_byte_offset += len(ln)\n",
    "        if ln[0] == '>':\n",
    "            if current_short_name is not None:\n",
    "                index.append((current_short_name, running_seq_length,\n",
    "                              current_byte_offset, line_length_excluding_ws,\n",
    "                              line_length_including_ws))\n",
    "            long_name = ln_stripped[1:]\n",
    "            current_short_name = long_name.split()[0]\n",
    "            current_byte_offset = running_byte_offset\n",
    "            running_seq_length = 0\n",
    "        else:\n",
    "            line_length_including_ws = max(line_length_including_ws, len(ln))\n",
    "            line_length_excluding_ws = max(line_length_excluding_ws, len(ln_stripped))\n",
    "            running_seq_length += len(ln_stripped)\n",
    "    if current_short_name is not None:\n",
    "        index.append((current_short_name, running_seq_length,\n",
    "                      current_byte_offset, line_length_excluding_ws,\n",
    "                      line_length_including_ws))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use it to index a small multi-FASTA file. We print out the index at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " fasta_example = StringIO(\n",
    "'''>sequence1_short_name with optional additional info after whitespace\n",
    "ACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA\n",
    "GCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAdAAAGGAACAAGCATCAAGCACGCAGC\n",
    "AATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGAT\n",
    ">sequence2_short_name with optional additional info after whitespace\n",
    "GCCCCAAACCCACTCCACCTTACTACCAGACAACCTTAGCCAAACCATTTACCCAAATAAAGTATAGGCG\n",
    "ATAGAAATTGAAACCTGGCGCAATAGATATAGTACCGCAAGGGAAAGATGAAAAATTATAACCAAGCATA\n",
    "ATATAG''')\n",
    "index_fasta(fasta_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the fields in those two records mean? Take the first record: ('sequence1_short_name', 194, 69, 70, 71). The fields from left to right are (1) the short name, (2) the length (in nucleotides), (3) the byte offset in the FASTA file of the first nucleotide of the sequence, (4) the maximum number of nucleotides per line, and (5) the maximum number of bytes per line, including whitespace. It's not hard to convince yourself that, if you know all these things, it's not hard to figure out the byte offset of any position in any of the sequences. (This is what the get member of the FastaIndexed class defined below does.)\n",
    "\n",
    "A typical way to build a FASTA index like this is to use SAMtools, specifically the samtools faidx command. This and all the other samtools commands are documented in its manual.\n",
    "\n",
    "When you use a tool like this to index a FASTA file, a new file containing the index is written with an additional .fai extension. E.g. if the FASTA file is named hg19.fa, then running samtools faidx hg19.fa will create a new file hg19.fa.fai containing the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing FASTA using PYSAM python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pysam Fastafile parser\n",
    "# Random access to fasta formatted files that have been previously indexed\n",
    "fasta = pysam.Fastafile(\"Ensembl.GRCh37.fasta\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with the names of reference sequences (contigs)\n",
    "fasta.references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reference sequences in the file\n",
    "fasta.nreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with the lengths of reference sequences\n",
    "fasta.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch sequences in a region\n",
    "#fasta['1'][248755121]\n",
    "fasta.fetch('1', 7, 17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link**: http://pysam.readthedocs.io/en/latest/api.html#pysam.FastaFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic format\n",
    "Here's a single sequencing read in FASTQ format:\n",
    "\n",
    "    @ERR294379.100739024 HS24_09441:8:2203:17450:94030#42/1\n",
    "    AGGGAGTCCACAGCACAGTCCAGACTCCCACCAGTTCTGACGAAATGATGAGAGCTCAGAAGTAACAGTTGCTTTCAGTCCCATAAAAACAGTCCTACAA\n",
    "    +\n",
    "    BDDEEF?FGFFFHGFFHHGHGGHCH@GHHHGFAHEGFEHGEFGHCCGGGFEGFGFFDFFHBGDGFHGEFGHFGHGFGFFFEHGGFGGDGHGFEEHFFHGE\n",
    "\n",
    "It's spread across four lines.  The four lines are:\n",
    "\n",
    "1. \"`@`\" followed by a read name\n",
    "2. Nucleotide sequence\n",
    "3. \"`+`\", possibly followed by some info, but ignored by virtually all tools\n",
    "4. Quality sequence (explained below)\n",
    "\n",
    "Here is a very simple Python function for parsing file of FASTQ records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fastq(f):\n",
    "    reads = []\n",
    "    while True:\n",
    "        first_line = f.readline()\n",
    "        if len(first_line) == 0:\n",
    "            break\n",
    "        name = first_line[1:].rstrip()\n",
    "        seq = f.readline().rstrip()\n",
    "        # skip + line\n",
    "        f.readline()\n",
    "        qual = f.readline().rstrip()\n",
    "        reads.append((name, seq, qual))\n",
    "        \n",
    "    return reads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_string = '''@ERR294379.100739024 HS24_09441:8:2203:17450:94030#42/1\n",
    "AGGGAGTCCACAGCACAGTCCAGACTCCCACCAGTTCTGACGAAATGATG\n",
    "+\n",
    "BDDEEF?FGFFFHGFFHHGHGGHCH@GHHHGFAHEGFEHGEFGHCCGGGF\n",
    "@ERR294379.136275489 HS24_09441:8:2311:1917:99340#42/1\n",
    "CTTAAGTATTTTGAAAGTTAACATAAGTTATTCTCAGAGAGACTGCTTTT\n",
    "+\n",
    "@@AHFF?EEDEAF?FEEGEFD?GGFEFGECGE?9H?EEABFAG9@CDGGF\n",
    "@ERR294379.97291341 HS24_09441:8:2201:10397:52549#42/1\n",
    "GGCTGCCATCAGTGAGCAAGTAAGAATTTGCAGAAATTTATTAGCACACT\n",
    "+\n",
    "CDAF<FFDEHEFDDFEEFDGDFCHD=GHG<GEDHDGJFHEFFGEFEE@GH'''\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "parse_fastq(StringIO(fastq_string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nucleotide string can sometimes contain the character \"N\".  N essentially means \"no confidence.\" The sequencer knows there's a nucleotide there but doesn't know whether it's an A, C, G or T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read name** <br/>\n",
    "Read names often contain information about:\n",
    "\n",
    "The scientific study for which the read was sequenced. E.g. the string ERR294379 (an SRA accession number) in the read names correspond to this study.\n",
    "The sequencing instrument, and the exact part of the sequencing instrument, where the DNA was sequenced. See the FASTQ format wikipedia article for specifics on how the Illumina software encodes this information.\n",
    "Whether the read is part of a paired-end read and, if so, which end it is. Paired-end reads will be discussed further below. The /1 you see at the end of the read names above indicate the read is the first end from a paired-end read.\n",
    "\n",
    "\n",
    "**Quality values** <br/>\n",
    "Quality values are probabilities. Each nucleotide in each sequencing read has an associated quality value. A nucleotide's quality value encodes the probability that the nucleotide was incorrectly called by the sequencing instrument and its software. If the nucleotide is A, the corresponding quality value encodes the probability that the nucleotide at that position is actually not an A.\n",
    "\n",
    "Quality values encoded in two senses: first, the relevant probabilities are rescaled using the Phread scale, which is a negative log scale. In other words if p us the probability that the nucleotide was incorrectly called, we encode this as Q where Q = -10 * log10(p).\n",
    "\n",
    "For example, if Q = 30, then p = 0.001, a 1-in-1000 chance that the nucleotide is wrong. If Q = 20, then p = 0.01, a 1-in-100 chance. If Q = 10, then p = 0.1, a 1-in-10 chance. And so on.\n",
    "\n",
    "Second, scaled quality values are rounded to the nearest integer and encoded using ASCII printable characters. For example, using the Phred33 encoding (which is by far the most common), a Q of 30 is encoded as the ASCII character with code 33 + 30 = 63, which is \"?\". A Q of 20 is encoded as the ASCII character with code 33 + 20 = 53, which is \"5\". And so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing FASTQ using PYSAM python module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream access to FASTQ formatted files\n",
    "fastq = pysam.FastxFile(\"example_human_Illumina.pe_1.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in fastq:\n",
    "    print(entry.name)\n",
    "    print(entry.sequence)\n",
    "    print(entry.comment)\n",
    "    print(entry.quality)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link**: http://pysam.readthedocs.io/en/latest/api.html#fastq-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDITIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class FastaOOB(Exception):\n",
    "    \"\"\" Out-of-bounds exception for FASTA sequences \"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "class FastaIndexed(object):\n",
    "    \"\"\" Encapsulates a set of indexed FASTA files.  Does not load the FASTA\n",
    "        files into memory but still allows the user to extract arbitrary\n",
    "        substrings, with the help of the index. \"\"\"\n",
    "    \n",
    "    __removeWs = re.compile(r'\\s+')\n",
    "    \n",
    "    def __init__(self, fafns):\n",
    "        self.fafhs = {}\n",
    "        self.faidxs = {}\n",
    "        self.chr2fh = {}\n",
    "        self.offset = {}\n",
    "        self.lens = {}\n",
    "        self.charsPerLine = {}\n",
    "        self.bytesPerLine = {}\n",
    "        \n",
    "        for fafn in fafns:\n",
    "            # Open FASTA file\n",
    "            self.fafhs[fafn] = fh = open(fafn, 'r')\n",
    "            # Parse corresponding .fai file\n",
    "            with open(fafn + '.fai') as idxfh:\n",
    "                for ln in idxfh:\n",
    "                    toks = ln.rstrip().split()\n",
    "                    if len(toks) == 0:\n",
    "                        continue\n",
    "                    assert len(toks) == 5\n",
    "                    # Parse and save the index line\n",
    "                    chr, ln, offset, charsPerLine, bytesPerLine = toks\n",
    "                    self.chr2fh[chr] = fh\n",
    "                    self.offset[chr] = int(offset) # 0-based\n",
    "                    self.lens[chr] = int(ln)\n",
    "                    self.charsPerLine[chr] = int(charsPerLine)\n",
    "                    self.bytesPerLine[chr] = int(bytesPerLine)\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        # Close all the open FASTA files\n",
    "        for fafh in self.fafhs.values():\n",
    "            fafh.close()\n",
    "    \n",
    "    def has_name(self, refid):\n",
    "        return refid in self.offset\n",
    "    \n",
    "    def name_iter(self):\n",
    "        return self.offset.keys()\n",
    "    \n",
    "    def length_of_ref(self, refid):\n",
    "        return self.lens[refid]\n",
    "    \n",
    "    def get(self, refid, start, ln):\n",
    "        ''' Return the specified substring of the reference. '''\n",
    "        assert refid in self.offset\n",
    "        if start + ln > self.lens[refid]:\n",
    "            raise ReferenceOOB('\"%s\" has length %d; tried to get [%d, %d)' % (refid, self.lens[refid], start, start + ln))\n",
    "        fh, offset, charsPerLine, bytesPerLine = \\\n",
    "            self.chr2fh[refid], self.offset[refid], \\\n",
    "            self.charsPerLine[refid], self.bytesPerLine[refid]\n",
    "        byteOff = offset\n",
    "        byteOff += (start // charsPerLine) * bytesPerLine\n",
    "        into = start % charsPerLine\n",
    "        byteOff += into\n",
    "        fh.seek(byteOff)\n",
    "        left = charsPerLine - into\n",
    "        # Count the number of line breaks interrupting the rest of the\n",
    "        # string we're trying to read\n",
    "        if ln < left:\n",
    "            return fh.read(ln)\n",
    "        else:\n",
    "            nbreaks = 1 + (ln - left) // charsPerLine\n",
    "            res = fh.read(ln + nbreaks * (bytesPerLine - charsPerLine))\n",
    "            res = re.sub(self.__removeWs, '', res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll write a new FASTA file\n",
    "with open('tmp.fa', 'w') as fh:\n",
    "    fh.write('''>sequence1_short_name with optional additional info after whitespace\n",
    "ACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA\n",
    "GCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGAACAAGCATCAAGCACGCAGC\n",
    "AATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGAT\n",
    ">sequence2_short_name with optional additional info after whitespace\n",
    "GCCCCAAACCCACTCCACCTTACTACCAGACAACCTTAGCCAAACCATTTACCCAAATAAAGTATAGGCG\n",
    "ATAGAAATTGAAACCTGGCGCAATAGATATAGTACCGCAAGGGAAAGATGAAAAATTATAACCAAGCATA\n",
    "ATATAG''')\n",
    "with open('tmp.fa') as fh:\n",
    "    idx = index_fasta(fh)\n",
    "with open('tmp.fa.fai', 'w') as fh:\n",
    "    fh.write('\\n'.join(['\\t'.join(map(str, x)) for x in idx]))\n",
    "with FastaIndexed(['tmp.fa']) as fa_idx:\n",
    "    print (fa_idx.get('sequence2_short_name', 100, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
